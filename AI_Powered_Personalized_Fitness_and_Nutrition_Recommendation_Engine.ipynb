{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNycezRAhMBBoRxR/dKnxcI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedSci/AI-Powered-Personalized-Fitness-and-Nutrition-Recommendation-Engine/blob/main/AI_Powered_Personalized_Fitness_and_Nutrition_Recommendation_Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Production Mode**"
      ],
      "metadata": {
        "id": "5ymTne-1slN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Production Mode with Google Colab**"
      ],
      "metadata": {
        "id": "lIIFLXX0tW_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "AI-Powered Personalized Fitness and Nutrition Recommendation Engine - Production-Ready Code for Google Colab\n",
        "\n",
        "This script implements a comprehensive AI model for generating personalized fitness and\n",
        "nutrition plans, specifically designed to run on Google Colab with data files stored\n",
        "in the user's Google Drive.\n",
        "\n",
        "Author: Mohamed Said Ibrahim\n",
        "Date: April 1, 2025\n",
        "Version: 1.1 (Colab Specific)\n",
        "\"\"\"\n",
        "\n",
        "# --- 1. Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, r2_score\n",
        "import joblib\n",
        "import logging\n",
        "import os\n",
        "from typing import Dict, List, Union, Tuple\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# --- 2. Configuration Management ---\n",
        "@dataclass\n",
        "class Configuration:\n",
        "    \"\"\"Configuration class to manage file paths and hyperparameters.\"\"\"\n",
        "    # Update this path to your Google Drive data folder\n",
        "    DRIVE_ROOT: str = '/content/drive/MyDrive'\n",
        "    PROJECT_FOLDER: str = 'Projects/Get_Fit_App/Ai_Model'\n",
        "    DATA_FOLDER: str = 'Data_Source'\n",
        "    DATA_DIR: str = os.path.join(DRIVE_ROOT, PROJECT_FOLDER, DATA_FOLDER)\n",
        "    Generated_Models_FOLDER: str = 'Generated_Models'\n",
        "    MODELS_DIR: str = os.path.join(DRIVE_ROOT, PROJECT_FOLDER, Generated_Models_FOLDER)\n",
        "    FITNESS_LEVEL_DATA_FILE: str = 'fitness_level_data_example.csv'\n",
        "    TRAINING_PARAMS_DATA_FILE: str = 'training_params_data_example.csv'\n",
        "    DIETARY_NEEDS_DATA_FILE: str = 'dietary_needs_data_example.csv'\n",
        "    EXERCISE_DATABASE_FILE: str = 'exercise_database_example.csv'\n",
        "    FITNESS_LEVEL_MODEL_NAME: str = 'fitness_level_model.pkl'\n",
        "    TRAINING_PARAMS_MODEL_NAME: str = 'training_params_model.pkl'\n",
        "    DIETARY_NEEDS_MODEL_NAME: str = 'dietary_needs_model.pkl'\n",
        "    N_SPLITS_CV: int = 5\n",
        "    RANDOM_STATE: int = 42\n",
        "    LOG_LEVEL: int = logging.INFO\n",
        "\n",
        "# Initialize configuration and logging\n",
        "config = Configuration()\n",
        "os.makedirs(config.MODELS_DIR, exist_ok=True)\n",
        "\n",
        "logging.basicConfig(level=config.LOG_LEVEL, format='%(asctime)s - %(levelname)s - %(module)s - %(message)s')\n",
        "\n",
        "# --- 3. Data Loading and Preprocessing Module ---\n",
        "class DataPreprocessor:\n",
        "    \"\"\"Handles loading, validation, and preprocessing of data.\"\"\"\n",
        "    def load_data(self, file_path: str) -> pd.DataFrame:\n",
        "        \"\"\"Loads data from a CSV file and performs basic validation.\"\"\"\n",
        "        try:\n",
        "            df = pd.read_csv(file_path)\n",
        "            if df.empty:\n",
        "                logging.warning(f\"Loaded data from {file_path} is empty.\")\n",
        "            return df\n",
        "        except FileNotFoundError:\n",
        "            logging.error(f\"Data file not found at: {file_path}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error loading data from {file_path}: {e}\")\n",
        "            raise\n",
        "\n",
        "    def preprocess_user_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Preprocesses user data for model training or inference.\"\"\"\n",
        "        logging.info(\"Preprocessing user data...\")\n",
        "        # Basic data cleaning (more specific cleaning might be needed based on data)\n",
        "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "        # Handle missing values (impute numerical with mean, categorical with mode)\n",
        "        for col in df.select_dtypes(include=np.number).columns:\n",
        "            df[col].fillna(df[col].mean(), inplace=True)\n",
        "        for col in df.select_dtypes(include='object').columns:\n",
        "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "        # Feature Engineering (example: BMI calculation)\n",
        "        if 'weight' in df.columns and 'height' in df.columns:\n",
        "            df['bmi'] = df['weight'] / (df['height'] / 100)**2\n",
        "\n",
        "        return df\n",
        "\n",
        "    def split_data(self, df: pd.DataFrame, target_column: Union[str, List[str]], test_size: float = 0.2) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
        "        \"\"\"Splits data into training and testing sets.\"\"\"\n",
        "        X = df.drop(columns=target_column, errors='ignore')\n",
        "        y = df[target_column] if isinstance(target_column, str) and target_column in df.columns else df[target_column] if isinstance(target_column, list) and all(col in df.columns for col in target_column) else None\n",
        "        if y is None:\n",
        "            raise ValueError(f\"Target column(s) '{target_column}' not found in DataFrame.\")\n",
        "        return train_test_split(X, y, test_size=test_size, random_state=config.RANDOM_STATE)\n",
        "\n",
        "    def create_preprocessing_pipeline(self, X: pd.DataFrame) -> ColumnTransformer:\n",
        "        \"\"\"Creates a preprocessing pipeline for numerical and categorical features.\"\"\"\n",
        "        numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "        categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "        numerical_transformer = StandardScaler()\n",
        "        categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numerical_transformer, numerical_features),\n",
        "                ('cat', categorical_transformer, categorical_features)])\n",
        "        return preprocessor\n",
        "\n",
        "# --- 4. Model Training Module ---\n",
        "class ModelTrainer:\n",
        "    \"\"\"Trains and evaluates machine learning models.\"\"\"\n",
        "    def __init__(self, model_type: str):\n",
        "        self.model_type = model_type\n",
        "        self.model = self._initialize_model()\n",
        "\n",
        "    def _initialize_model(self):\n",
        "        \"\"\"Initializes the appropriate model based on the model type.\"\"\"\n",
        "        if self.model_type == 'fitness_level':\n",
        "            return RandomForestClassifier(random_state=config.RANDOM_STATE)\n",
        "        elif self.model_type == 'training_params':\n",
        "            return RandomForestRegressor(random_state=config.RANDOM_STATE)\n",
        "        elif self.model_type == 'dietary_needs':\n",
        "            return LinearRegression()\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "    def train_model(self, X_train: pd.DataFrame, y_train: pd.Series):\n",
        "        \"\"\"Trains the specified model.\"\"\"\n",
        "        logging.info(f\"Training the {self.model_type} model...\")\n",
        "        self.model.fit(X_train, y_train)\n",
        "        logging.info(f\"{self.model_type} model training complete.\")\n",
        "\n",
        "    def evaluate_model(self, X_test: pd.DataFrame, y_test: pd.Series):\n",
        "        \"\"\"Evaluates the trained model based on the model type.\"\"\"\n",
        "        logging.info(f\"Evaluating the {self.model_type} model...\")\n",
        "        if self.model_type == 'fitness_level':\n",
        "            y_pred = self.model.predict(X_test)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            report = classification_report(y_test, y_pred)\n",
        "            logging.info(f\"{self.model_type} model accuracy: {accuracy:.4f}\")\n",
        "            logging.info(f\"{self.model_type} model classification report:\\n{report}\")\n",
        "            return accuracy\n",
        "        elif self.model_type == 'training_params':\n",
        "            y_pred = self.model.predict(X_test)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            logging.info(f\"{self.model_type} model mean squared error: {mse:.4f}\")\n",
        "            logging.info(f\"{self.model_type} model R-squared: {r2:.4f}\")\n",
        "            return mse\n",
        "        elif self.model_type == 'dietary_needs':\n",
        "            y_pred = self.model.predict(X_test)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            logging.info(f\"{self.model_type} model mean squared error: {mse:.4f}\")\n",
        "            logging.info(f\"{self.model_type} model R-squared: {r2:.4f}\")\n",
        "            return mse\n",
        "        return None\n",
        "\n",
        "    def save_model(self, filename: str):\n",
        "        \"\"\"Saves the trained model to the specified path.\"\"\"\n",
        "        model_path = os.path.join(config.MODELS_DIR, filename)\n",
        "        try:\n",
        "            joblib.dump(self.model, model_path)\n",
        "            logging.info(f\"{self.model_type} model saved to: {model_path}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error saving {self.model_type} model: {e}\")\n",
        "\n",
        "    def load_model(self, filename: str):\n",
        "        \"\"\"Loads a trained model from the specified path.\"\"\"\n",
        "        model_path = os.path.join(config.MODELS_DIR, filename)\n",
        "        try:\n",
        "            self.model = joblib.load(model_path)\n",
        "            logging.info(f\"{self.model_type} model loaded from: {model_path}\")\n",
        "        except FileNotFoundError:\n",
        "            logging.error(f\"Model file not found at: {model_path}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error loading {self.model_type} model: {e}\")\n",
        "\n",
        "# --- 5. Hyperparameter Tuning Module ---\n",
        "class HyperparameterTuner:\n",
        "    \"\"\"Tunes the hyperparameters of the AI models using GridSearchCV.\"\"\"\n",
        "    def __init__(self, model_type: str, model, param_grid: Dict):\n",
        "        self.model_type = model_type\n",
        "        self.model = model\n",
        "        self.param_grid = param_grid\n",
        "        self.best_model = None\n",
        "\n",
        "    def tune_hyperparameters(self, X_train: pd.DataFrame, y_train: pd.Series, scoring: str = None, cv: int = config.N_SPLITS_CV):\n",
        "        \"\"\"Performs hyperparameter tuning using GridSearchCV.\"\"\"\n",
        "        logging.info(f\"Tuning hyperparameters for the {self.model_type} model...\")\n",
        "        grid_search = GridSearchCV(estimator=self.model, param_grid=self.param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        self.best_model = grid_search.best_estimator_\n",
        "        logging.info(f\"Best hyperparameters for {self.model_type}: {grid_search.best_params_}\")\n",
        "\n",
        "    def get_best_model(self):\n",
        "        \"\"\"Returns the best performing model after tuning.\"\"\"\n",
        "        return self.best_model\n",
        "\n",
        "# --- 6. Prediction Module ---\n",
        "class PredictionEngine:\n",
        "    \"\"\"Handles loading trained models and making predictions.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.fitness_level_model = None\n",
        "        self.training_params_model = None\n",
        "        self.dietary_needs_model = None\n",
        "        self.preprocessor = DataPreprocessor()\n",
        "        self.feature_encoders = {} # Store fitted preprocessors\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"Loads all necessary trained models.\"\"\"\n",
        "        try:\n",
        "            trainer_fitness = ModelTrainer(model_type='fitness_level')\n",
        "            trainer_fitness.load_model(os.path.join(config.MODELS_DIR,config.FITNESS_LEVEL_MODEL_NAME))\n",
        "            self.fitness_level_model = trainer_fitness.model\n",
        "\n",
        "            trainer_training_params = ModelTrainer(model_type='training_params')\n",
        "            trainer_training_params.load_model(os.path.join(config.MODELS_DIR,config.TRAINING_PARAMS_MODEL_NAME))\n",
        "            self.training_params_model = trainer_training_params.model\n",
        "\n",
        "            trainer_dietary_needs = ModelTrainer(model_type='dietary_needs')\n",
        "            trainer_dietary_needs.load_model(os.path.join(config.MODELS_DIR,config.DIETARY_NEEDS_MODEL_NAME))\n",
        "            self.dietary_needs_model = trainer_dietary_needs.model\n",
        "\n",
        "            # Load the fitted preprocessors\n",
        "            self.feature_encoders['fitness_level'] = joblib.load(os.path.join(config.MODELS_DIR, 'fitness_preprocessor.pkl'))\n",
        "            self.feature_encoders['training_params'] = joblib.load(os.path.join(config.MODELS_DIR, 'training_preprocessor.pkl'))\n",
        "            self.feature_encoders['dietary_needs'] = joblib.load(os.path.join(config.MODELS_DIR, 'dietary_preprocessor.pkl'))\n",
        "\n",
        "            logging.info(\"All models loaded successfully.\")\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            logging.error(f\"Error loading models: {e}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"An unexpected error occurred while loading models: {e}\")\n",
        "            raise\n",
        "\n",
        "    def predict_fitness_level(self, user_profile: Dict) -> str:\n",
        "        \"\"\"Predicts the fitness level of a user.\"\"\"\n",
        "        if self.fitness_level_model is None or 'fitness_level' not in self.feature_encoders:\n",
        "            logging.error(\"Fitness level model or preprocessor not loaded.\")\n",
        "            return \"Error\"\n",
        "        try:\n",
        "            user_df = pd.DataFrame([user_profile])\n",
        "            # Ensure only features used during training are selected and ordered correctly\n",
        "            feature_names = joblib.load(os.path.join(config.MODELS_DIR, 'fitness_feature_names.pkl'))\n",
        "            user_df = user_df[feature_names]\n",
        "            processed_data = self.feature_encoders['fitness_level'].transform(user_df)\n",
        "            prediction = self.fitness_level_model.predict(processed_data)[0]\n",
        "            return prediction\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error predicting fitness level: {e}\")\n",
        "            return \"Error\"\n",
        "\n",
        "    def predict_training_plan(self, user_profile: Dict) -> Dict:\n",
        "        \"\"\"Predicts the training parameters for a user.\"\"\"\n",
        "        if self.training_params_model is None or 'training_params' not in self.feature_encoders:\n",
        "            logging.error(\"Training parameters model or preprocessor not loaded.\")\n",
        "            return {\"error\": \"Model not loaded\"}\n",
        "        try:\n",
        "            user_df = pd.DataFrame([user_profile])\n",
        "            feature_names = joblib.load(os.path.join(config.MODELS_DIR, 'training_params_feature_names.pkl'))\n",
        "            user_df = user_df[feature_names]\n",
        "            processed_data = self.feature_encoders['training_params'].transform(user_df)\n",
        "            prediction = self.training_params_model.predict(processed_data)[0] # Assuming output is an array\n",
        "            # Map the predicted parameters to a structured training plan\n",
        "            # This mapping needs to be consistent with how the model was trained\n",
        "            plan = {\n",
        "                \"workout_frequency\": \"3 days per week (example)\",\n",
        "                \"exercises\": [\n",
        "                    {\"name\": \"Barbell Squat\", \"sets\": round(prediction[0]), \"repetitions\": round(prediction[1])},\n",
        "                    {\"name\": \"Bench Press\", \"sets\": round(prediction[2]), \"repetitions\": round(prediction[3])},\n",
        "                    # ... map other predicted parameters to exercises\n",
        "                ]\n",
        "            }\n",
        "            return plan\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error predicting training plan: {e}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def predict_dietary_needs(self, user_profile: Dict) -> Dict:\n",
        "        \"\"\"Predicts the dietary needs (calories and macros) for a user.\"\"\"\n",
        "        if self.dietary_needs_model is None or 'dietary_needs' not in self.feature_encoders:\n",
        "            logging.error(\"Dietary needs model or preprocessor not loaded.\")\n",
        "            return {\"error\": \"Model not loaded\"}\n",
        "        try:\n",
        "            user_df = pd.DataFrame([user_profile])\n",
        "            feature_names = joblib.load(os.path.join(config.MODELS_DIR, 'dietary_needs_feature_names.pkl'))\n",
        "            user_df = user_df[feature_names]\n",
        "            processed_data = self.feature_encoders['dietary_needs'].transform(user_df)\n",
        "            prediction = self.dietary_needs_model.predict(processed_data)[0] # Assuming output is [calories, protein, carbs, fat]\n",
        "            needs = {\n",
        "                \"daily_calories\": round(prediction[0]),\n",
        "                \"macronutrient_targets\": {\n",
        "                    \"protein\": round(prediction[1]),\n",
        "                    \"carbs\": round(prediction[2]),\n",
        "                    \"fat\": round(prediction[3])\n",
        "                }\n",
        "            }\n",
        "            return needs\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error predicting dietary needs: {e}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "# --- 7. Training Function ---\n",
        "def train_models(config: Configuration):\n",
        "    \"\"\"Trains and saves the AI models.\"\"\"\n",
        "    preprocessor = DataPreprocessor()\n",
        "\n",
        "    # --- Train Fitness Level Classification Model ---\n",
        "    try:\n",
        "        fitness_data = preprocessor.load_data(os.path.join(config.DATA_DIR, config.FITNESS_LEVEL_DATA_FILE))\n",
        "        fitness_data = preprocessor.preprocess_user_data(fitness_data)\n",
        "        X_fitness, y_fitness = fitness_data.drop('fitness_level', axis=1), fitness_data['fitness_level']\n",
        "        X_train_fitness, X_test_fitness, y_train_fitness, y_test_fitness = preprocessor.split_data(fitness_data, 'fitness_level')\n",
        "\n",
        "        fitness_preprocessor = preprocessor.create_preprocessing_pipeline(X_train_fitness)\n",
        "        X_train_processed_fitness = fitness_preprocessor.fit_transform(X_train_fitness)\n",
        "        X_test_processed_fitness = fitness_preprocessor.transform(X_test_fitness)\n",
        "\n",
        "        trainer_fitness = ModelTrainer(model_type='fitness_level')\n",
        "        trainer_fitness.train_model(X_train_processed_fitness, y_train_fitness)\n",
        "        trainer_fitness.evaluate_model(X_test_processed_fitness, y_test_fitness)\n",
        "        trainer_fitness.save_model(os.path.join(config.MODELS_DIR,config.FITNESS_LEVEL_MODEL_NAME))\n",
        "        joblib.dump(fitness_preprocessor, os.path.join(config.MODELS_DIR, 'fitness_preprocessor.pkl'))\n",
        "        joblib.dump(X_train_fitness.columns.tolist(), os.path.join(config.MODELS_DIR, 'fitness_feature_names.pkl'))\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        logging.warning(\"Fitness level training data not found. Skipping training.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error training fitness level model: {e}\")\n",
        "\n",
        "    # --- Train Training Parameters Regression Model ---\n",
        "    try:\n",
        "        training_params_data = preprocessor.load_data(os.path.join(config.DATA_DIR, config.TRAINING_PARAMS_DATA_FILE))\n",
        "        training_params_data = preprocessor.preprocess_user_data(training_params_data)\n",
        "        target_columns_tp = ['squat_sets', 'squat_reps', 'bench_sets', 'bench_reps'] # Example targets\n",
        "        X_training_params, y_training_params = training_params_data.drop(target_columns_tp, axis=1, errors='ignore'), training_params_data[target_columns_tp]\n",
        "        X_train_tp, X_test_tp, y_train_tp, y_test_tp = preprocessor.split_data(training_params_data, target_columns_tp)\n",
        "\n",
        "        training_preprocessor = preprocessor.create_preprocessing_pipeline(X_train_tp)\n",
        "        X_train_processed_tp = training_preprocessor.fit_transform(X_train_tp)\n",
        "        X_test_processed_tp = training_preprocessor.transform(X_test_tp)\n",
        "\n",
        "        trainer_training_params = ModelTrainer(model_type='training_params')\n",
        "        trainer_training_params.train_model(X_train_processed_tp, y_train_tp)\n",
        "        trainer_training_params.evaluate_model(X_test_processed_tp, y_test_tp)\n",
        "        trainer_training_params.save_model(os.path.join(config.MODELS_DIR,config.TRAINING_PARAMS_MODEL_NAME))\n",
        "        joblib.dump(training_preprocessor, os.path.join(config.MODELS_DIR, 'training_preprocessor.pkl'))\n",
        "        joblib.dump(X_train_tp.columns.tolist(), os.path.join(config.MODELS_DIR, 'training_params_feature_names.pkl'))\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        logging.warning(\"Training parameters data not found. Skipping training.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error training training parameters model: {e}\")\n",
        "\n",
        "    # --- Train Dietary Needs Regression Model ---\n",
        "    try:\n",
        "        dietary_needs_data = preprocessor.load_data(os.path.join(config.DATA_DIR, config.DIETARY_NEEDS_DATA_FILE))\n",
        "        dietary_needs_data = preprocessor.preprocess_user_data(dietary_needs_data)\n",
        "        target_columns_dn = ['calories', 'protein', 'carbs', 'fat']\n",
        "        X_dietary_needs, y_dietary_needs = dietary_needs_data.drop(target_columns_dn, axis=1, errors='ignore'), dietary_needs_data[target_columns_dn]\n",
        "        X_train_dn, X_test_dn, y_train_dn, y_test_dn = preprocessor.split_data(dietary_needs_data, target_columns_dn)\n",
        "\n",
        "        dietary_preprocessor = preprocessor.create_preprocessing_pipeline(X_train_dn)\n",
        "        X_train_processed_dn = dietary_preprocessor.fit_transform(X_train_dn)\n",
        "        X_test_processed_dn = dietary_preprocessor.transform(X_test_dn)\n",
        "\n",
        "        trainer_dietary_needs = ModelTrainer(model_type='dietary_needs')\n",
        "        trainer_dietary_needs.train_model(X_train_processed_dn, y_train_dn)\n",
        "        trainer_dietary_needs.evaluate_model(X_test_processed_dn, y_test_dn)\n",
        "        trainer_dietary_needs.save_model(os.path.join(config.MODELS_DIR,config.DIETARY_NEEDS_MODEL_NAME))\n",
        "        joblib.dump(dietary_preprocessor, os.path.join(config.MODELS_DIR, 'dietary_preprocessor.pkl'))\n",
        "        joblib.dump(X_train_dn.columns.tolist(), os.path.join(config.MODELS_DIR, 'dietary_needs_feature_names.pkl'))\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        logging.warning(\"Dietary needs training data not found. Skipping training.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error training dietary needs model: {e}\")\n",
        "\n",
        "# --- 8. Main Function to Run Predictions ---\n",
        "def main():\n",
        "    \"\"\"Loads trained models and demonstrates prediction for a sample user.\"\"\"\n",
        "    prediction_engine = PredictionEngine()\n",
        "    try:\n",
        "        prediction_engine.load_models()\n",
        "\n",
        "        # Example user profile (replace with actual user input)\n",
        "        sample_user_profile = {\n",
        "            \"age\": 30,\n",
        "            \"gender\": \"male\",\n",
        "            \"weight\": 80,  # kg\n",
        "            \"height\": 180, # cm\n",
        "            \"exercise_capabilities\": {\"pushups\": 10, \"squats\": 20, \"bench_press_weight\": 60},\n",
        "            \"country_of_residence\": \"Egypt\",\n",
        "            \"target_goal\": \"building mass and strength\"\n",
        "        }\n",
        "\n",
        "        fitness_level = prediction_engine.predict_fitness_level(sample_user_profile)\n",
        "        print(f\"\\nPredicted Fitness Level: {fitness_level}\")\n",
        "\n",
        "        training_plan = prediction_engine.predict_training_plan(sample_user_profile)\n",
        "        print(\"\\n--- Predicted Training Plan ---\")\n",
        "        print(training_plan)\n",
        "\n",
        "        dietary_needs = prediction_engine.predict_dietary_needs(sample_user_profile)\n",
        "        print(\"\\n--- Predicted Dietary Needs ---\")\n",
        "        print(dietary_needs)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during prediction: {e}\")\n",
        "\n",
        "# --- 9. Conceptual Deployment (Illustrative) ---\n",
        "def deploy_model_conceptual(config: Configuration):\n",
        "    \"\"\"\n",
        "    Conceptual deployment function. In a real scenario, this would involve:\n",
        "    - Containerization (e.g., using Docker)\n",
        "    - Setting up an API endpoint (e.g., using Flask or FastAPI)\n",
        "    - Deploying to a cloud platform (e.g., AWS, Google Cloud, Azure)\n",
        "    \"\"\"\n",
        "    logging.info(\"Conceptual model deployment started...\")\n",
        "    logging.info(f\"Trained models are saved in: {config.MODELS_DIR}\")\n",
        "    # In a real deployment, you would load these models in your API service\n",
        "    # and use them to serve prediction requests.\n",
        "    logging.info(\"Conceptual model deployment finished.\")\n",
        "\n",
        "# --- 10. Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    # To train the models, uncomment the following line:\n",
        "    train_models(config)\n",
        "\n",
        "    # To run predictions using the trained models:\n",
        "    main()\n",
        "\n",
        "    # To simulate deployment (conceptual):\n",
        "    deploy_model_conceptual(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpCVknrV41Yo",
        "outputId": "07ff4bcf-9317-48b8-b3e7-279bb001ebeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-9c3489977b7a>:86: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "<ipython-input-4-9c3489977b7a>:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "<ipython-input-4-9c3489977b7a>:86: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "<ipython-input-4-9c3489977b7a>:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "<ipython-input-4-9c3489977b7a>:86: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "<ipython-input-4-9c3489977b7a>:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "ERROR:root:Error predicting fitness level: \"['pushups', 'squats', 'plank_duration', 'running_endurance', 'weight_lifted_squat', 'bmi'] not in index\"\n",
            "ERROR:root:Error predicting training plan: \"['pushups', 'squats', 'weight_lifted_squat_max', 'weight_lifted_bench_max', 'bmi'] not in index\"\n",
            "ERROR:root:Error predicting dietary needs: \"['activity_level', 'pushups', 'squats', 'bmi'] not in index\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted Fitness Level: Error\n",
            "\n",
            "--- Predicted Training Plan ---\n",
            "{'error': '\"[\\'pushups\\', \\'squats\\', \\'weight_lifted_squat_max\\', \\'weight_lifted_bench_max\\', \\'bmi\\'] not in index\"'}\n",
            "\n",
            "--- Predicted Dietary Needs ---\n",
            "{'error': '\"[\\'activity_level\\', \\'pushups\\', \\'squats\\', \\'bmi\\'] not in index\"'}\n"
          ]
        }
      ]
    }
  ]
}